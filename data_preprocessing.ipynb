{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_PATH = '/home/chrisams/Documents/datasets/data_TAIM/raw'\n",
    "SAVE_DATA_PATH = '/home/chrisams/Documents/datasets/data_TAIM/processed/'\n",
    "COLUMNS = [\n",
    "    'Fecha Hora (YYYY-MM-DD HH:MM)',\n",
    "    'Velocidad de viento en 20.0 metros [mean,m/s]',\n",
    "    'Velocidad de viento en 10.0 metros [mean,m/s]',\n",
    "]\n",
    "V20 = 'Velocidad de viento en 20.0 metros [mean,m/s]'\n",
    "V10 = 'Velocidad de viento en 10.0 metros [mean,m/s]'\n",
    "STATS_PATH = '/home/chrisams/Documents/datasets/data_TAIM/stats.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all the data files.\n",
    "for path, _, file_names in os.walk(RAW_DATA_PATH):\n",
    "    eolic_plants_names = [None] * len(file_names)\n",
    "    eolic_plants_df = [None] * len(file_names)\n",
    "    for i, file_name in enumerate(file_names):\n",
    "        print('{} have index: {}'.format(file_name, i))\n",
    "        full_path = os.path.join(path, file_name)\n",
    "        eolic_plants_df[i] = pd.read_csv(full_path)\n",
    "        eolic_plants_names[i] = file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data and keep only useful columns and rows.\n",
    "\n",
    "min_date = None\n",
    "max_date = None\n",
    "\n",
    "for i in range(len(eolic_plants_df)):\n",
    "    plant =  eolic_plants_df[i]\n",
    "    plant = plant[COLUMNS].set_index(\\\n",
    "                pd.DatetimeIndex(plant['Fecha Hora (YYYY-MM-DD HH:MM)'])\\\n",
    "            ).iloc[:, 1:]\n",
    "    v10_mean = plant[V10].mean()\n",
    "    v20_mean = plant[V20].mean()\n",
    "    alpha = np.log(v10_mean / v20_mean) / np.log(10 / 20)\n",
    "    \n",
    "    plant['85m_speed'] = plant[V20] * np.power(85 / 20, alpha)\n",
    "    \n",
    "    current_min_date = plant.index.min()\n",
    "    current_max_date = plant.index.max()\n",
    "    \n",
    "    if min_date:\n",
    "        if min_date < current_min_date:\n",
    "            min_date = current_min_date\n",
    "    else:\n",
    "        min_date = current_min_date\n",
    "    \n",
    "    if max_date:\n",
    "        if max_date > current_max_date:\n",
    "            max_date = current_max_date\n",
    "    else:\n",
    "        max_date = current_max_date\n",
    "\n",
    "    eolic_plants_df[i] = plant['85m_speed']\n",
    "\n",
    "# Normalize data and keep statistics.\n",
    "stats_dict = {}\n",
    "for i in range(len(eolic_plants_df)):\n",
    "    plant = eolic_plants_df[i][min_date:max_date]\n",
    "    mean = plant.mean()\n",
    "    std = plant.std()\n",
    "    eolic_plants_df[i] = (plant - mean) / std\n",
    "    stats_dict[eolic_plants_names[i]] = {'mean': mean, 'std': std}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data and statistics.\n",
    "for i, plant in enumerate(eolic_plants_df):\n",
    "    plant.to_csv(os.path.join(SAVE_DATA_PATH, eolic_plants_names[i]))\n",
    "\n",
    "with open(STATS_PATH, 'wb') as fp:\n",
    "    pickle.dump(stats_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_resample_data(data_path, plant_name, resample_rule, n_rows,\\\n",
    "                       date_start=None, date_end=None):\n",
    "    print('Reading {}...'.format(plant_name))\n",
    "    data = pd.read_csv(os.path.join(data_path, plant_name),\\\n",
    "                       index_col=0, names=['85m_speed'], parse_dates=True)\n",
    "    data = data.resample(resample_rule).mean().interpolate(method='time')\n",
    "    if date_start and date_end:\n",
    "        data = data[date_start:date_end]\n",
    "    data = data['85m_speed'].values\n",
    "    if n_rows:\n",
    "        data = data[:n_rows]\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_data(data_path, n_plants, p, resample_rule='10T', n_rows=None,\\\n",
    "              date_start=None, date_end=None, plant_names=None):\n",
    "    \"\"\"\n",
    "    data_path: directory where the data is saved.\n",
    "    n_plants: number of plants to load (K).\n",
    "    resample: resample rule for data aggregation.\n",
    "    date_start: initial date of data (YYYY-MM).\n",
    "    date_end: end date of data (YYYY-MM).\n",
    "    plant_names: list with the eolic plants to load.\n",
    "    \"\"\"\n",
    "    if plant_names is not None:\n",
    "        data = [None] * len(plant_names)\n",
    "        for i, plant_name in enumerate(plant_names):\n",
    "            data[i] = read_resample_data(data_path, plant_name, resample_rule,\\\n",
    "                                         n_rows, date_start=date_start, date_end=date_end)\n",
    "    else:    \n",
    "        data = [None] * n_plants\n",
    "        for path, _, file_names in os.walk(data_path):\n",
    "            for i in range(len(file_names)):\n",
    "                if i + 1 > n_plants:\n",
    "                    break\n",
    "                data[i] = read_resample_data(data_path, file_names[i], resample_rule,\\\n",
    "                                             n_rows, date_start=date_start, date_end=date_end)\n",
    "    \n",
    "    data = np.stack(data, axis=0)\n",
    "    #test_data = data\n",
    "    \n",
    "    if p > 0:\n",
    "        X = np.zeros((n_plants * p, data.shape[1] - p))\n",
    "        j = 0\n",
    "        for i in range(p, data.shape[1]):\n",
    "            for t in range(p):\n",
    "                X[t * n_plants:(t + 1) * n_plants, j] = data[:, (i - 1) - t]\n",
    "            j += 1\n",
    "    else:\n",
    "        X = data\n",
    "    \n",
    "    data = data[:, p:]\n",
    "    \n",
    "    return data, X\n",
    "    #return data, X, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/chrisams/Documents/datasets/data_TAIM/processed/'\n",
    "K = 2\n",
    "p = 1\n",
    "n_rows = None\n",
    "date_start = '2011-05'\n",
    "date_end = '2011-06'\n",
    "plant_names = [\n",
    "    'd05b_2010-06-19_2018-03-05.csv',\n",
    "    'd01_2009-07-12_2018-01-17.csv',\n",
    "]\n",
    "#Y0, X, test = load_data(DATA_PATH, K, p, resample_rule='10T', n_rows=n_rows, date_start=date_start,\\\n",
    "#                        date_end=date_end)\n",
    "Y0, X = load_data(DATA_PATH, K, p, resample_rule='10T', n_rows=n_rows, date_start=date_start,\\\n",
    "                        date_end=date_end, plant_names=plant_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('YO shape: {} and should be: {} x {}'.format(Y0.shape, K, Y0.shape[1]))\n",
    "print('X shape: {} and should be: {} x {}'.format(X.shape, K * p, Y0.shape[1]))\n",
    "c = 5\n",
    "c_ = 0\n",
    "for i in range(p, test.shape[1]):\n",
    "    print('YO: {} = DATA: {}'.format(Y0[:, i - p], test[:, i]))\n",
    "    for t in range(p):\n",
    "        print('X: {} = DATA: {}'.format(X[t * K: (t + 1) * K, i - p], test[:, i - (t + 1)]))\n",
    "    c_ += 1\n",
    "    if c_ >= c:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test')\n",
    "print(test[:, :6])\n",
    "print('Y0')\n",
    "print(Y0[:, :6])\n",
    "print('X')\n",
    "print(X[:, :6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(STATS_PATH, 'rb') as f:\n",
    "    stats = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of data per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all the data files.\n",
    "for path, _, file_names in os.walk(RAW_DATA_PATH):\n",
    "    eolic_plants_names = [None] * len(file_names)\n",
    "    eolic_plants_df = [None] * len(file_names)\n",
    "    for i, file_name in enumerate(file_names):\n",
    "        print('{} have index: {}'.format(file_name, i))\n",
    "        full_path = os.path.join(path, file_name)\n",
    "        plant = pd.read_csv(full_path)\n",
    "        plant = plant[COLUMNS].set_index(\\\n",
    "                pd.DatetimeIndex(plant['Fecha Hora (YYYY-MM-DD HH:MM)'])\\\n",
    "            ).iloc[:, 1:]\n",
    "        eolic_plants_df[i] = plant[V20]\n",
    "        eolic_plants_names[i] = file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eolic_plants_df[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eolic_plants_df[0]['2011-05':'2011-06']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2012'\n",
    "for i in range(len(eolic_plants_df)):\n",
    "    print(eolic_plants_names[i])\n",
    "    df = eolic_plants_df[i]\n",
    "    zeros = df[year][df[year] == 0]\n",
    "    print('Data count:')\n",
    "    print(df[year].groupby(df[year].index.month).count())\n",
    "    print('Zeros count:')\n",
    "    print(zeros.groupby(zeros.index.month).count())\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolated time is equal to original time if data is complete.-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_original = eolic_plants_df[i]['2011-5'][V20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_interpolated = df1.interpolate(method='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(df1_original.values == df1_interpolated.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
