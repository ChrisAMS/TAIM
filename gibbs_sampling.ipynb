{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import scipy.stats as stats\n",
    "from utils import load_data, val_loglhood, loglhood, jump_dst, reconstruct_coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gibbs Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gibbs_sampling(iters, data_path, K, p, q, mh_iters=1, n_rows=None, debug=False, method='normal'):\n",
    "    \"\"\"\n",
    "    iters: quantity of samples of A and U.\n",
    "    data_path: path where data is saved.\n",
    "    K: number of plants (n_plants in load_data function).\n",
    "    p: past time to be considered.\n",
    "    q: jumping distribution for parameters (from scipy.stats).\n",
    "    mh_iters: haw many samples do with Metropolis Hastings.\n",
    "    n_rows: how many rows of the data to consider.\n",
    "    debug: debug mode.\n",
    "    method: normal - use a jumping distribution from scipy.stats\n",
    "            personalized - use the jumping distribution personalized by us.\n",
    "    \"\"\"\n",
    "    print('Loading data...')\n",
    "    Y0, X = load_data(data_path, K, p, resample_rule='10T', n_rows=n_rows)\n",
    "    if debug:\n",
    "        print('Y0 shape: {}'.format(Y0.shape))\n",
    "        print('X shape: {}'.format(X.shape))\n",
    "\n",
    "    # Theta is the vector of all parameters that will be sampled.\n",
    "    # A and CovU are reshaped to a 1-D vector theta.\n",
    "    # Note that this theta change dimensionality when using personalized.\n",
    "    theta = init_parameters(K, p, q, Y0, X, debug=debug, method=method)\n",
    "\n",
    "    if debug:\n",
    "        print('Parameters intialized!')\n",
    "    samples = []\n",
    "    for i in range(iters):\n",
    "        start_it = time.time()\n",
    "        print('Iteration {}'.format(i))\n",
    "\n",
    "        # Loop over all parameters and for each parameter theta[j],\n",
    "        # do a MH sampling over the distribution of theta[j] given theta[-j].\n",
    "        for j in range(theta.shape[0]):\n",
    "            start = time.time()\n",
    "            mh_samples = metropolis_hastings(theta, j, q, mh_iters, Y0, X, K, debug, method=method)\n",
    "            end = time.time()\n",
    "            print('Time for sampling theta[{}]: {}'.format(j, end - start))\n",
    "            # When mh_iters > 1, mh_samples contain mh_iters samples, so a random\n",
    "            # choice (uniform) is done for selection of the new theta.\n",
    "            theta[j] = np.random.choice(mh_samples)\n",
    "\n",
    "        if p == 1 and method == 'personalized':\n",
    "            A, CovU = reconstruct_coefs(theta, K)\n",
    "        else:\n",
    "            A    = np.reshape(theta[:p*K**2],(K*p,K)).swapaxes(0,1)\n",
    "            CovU = np.reshape(theta[p*K**2:],(K,K)).swapaxes(0,1)\n",
    "            CovU = np.dot(CovU.T,CovU)\n",
    "\n",
    "        samples.append([A, CovU])\n",
    "        end_it = time.time()\n",
    "        print('Time for iteration {}: {}'.format(i, end_it - start_it))\n",
    "    print('Finished!')\n",
    "    return samples\n",
    "        \n",
    "    \n",
    "def init_parameters(K, p, q, Y0, X, method='normal', debug=False):\n",
    "    \"\"\"\n",
    "    Initialization of parameters. This functions search a matrix A\n",
    "    and a matrix CovU that satisfy some conditions that A and CovU\n",
    "    must satisfy.\n",
    "    \"\"\"\n",
    "    if debug:\n",
    "        print('Initializing parameters...')\n",
    "    while True:\n",
    "        theta = np.zeros(K ** 2 * (p + 1))\n",
    "        for i in range(theta.shape[0]):\n",
    "            theta[i] = q.rvs()\n",
    "\n",
    "        # Force CovU to be positive semidefinite.\n",
    "        covu = np.reshape(theta[-K**2:], (K, K)).T\n",
    "        covu = np.dot(covu.T, covu)\n",
    "        theta[-K**2:] = np.reshape(covu, K**2)\n",
    "        \n",
    "        lk = val_loglhood(theta, Y0, X, debug, method=method, init_params=True)\n",
    "        if debug:\n",
    "            print('LK = {}'.format(lk))\n",
    "        if lk != -np.inf:\n",
    "            print('lk init: {}'.format(lk))\n",
    "            if p == 1 and method == 'personalized':\n",
    "                A = np.reshape(theta[:p*K**2],(K*p,K)).swapaxes(0,1)\n",
    "                eig_valuesA, eig_vecA = np.linalg.eig(A)\n",
    "                eig_valuesB, eig_vecB = np.linalg.eig(covu)\n",
    "                theta = np.concatenate((eig_vecA.reshape(-1), eig_vecB.reshape(-1),\n",
    "                                        eig_valuesA, eig_valuesB))\n",
    "                if np.all(np.isreal(eig_valuesA)):\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "    return theta\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metropolis Hastings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metropolis Hastings\n",
    "\n",
    "def metropolis_hastings(theta, j, q, iters, Y0, X, K, debug, method='normal'):\n",
    "    \"\"\"\n",
    "    theta: theta vector with all parameters.\n",
    "    j: theta index of the parameter currently been sampled.\n",
    "    q: jumping distribution.\n",
    "    \"\"\"\n",
    "    user_std = 1\n",
    "    samples_mh = [theta[j]] # start sample.\n",
    "    lk_old = val_loglhood(theta, Y0, X, debug, method=method)\n",
    "    print('init lk: {}'.format(lk_old))\n",
    "    for t in range(iters):\n",
    "        lk_new = -np.inf\n",
    "        c = -1\n",
    "        while lk_new == -np.inf:\n",
    "            c += 1\n",
    "            if method == 'normal':\n",
    "                x_new = q.rvs(loc=samples_mh[-1], scale=1)\n",
    "                theta[j] = x_new\n",
    "            elif method == 'personalized':\n",
    "                theta, q_eval_new, q_eval_old = jump_dst(theta, j, user_std, K)\n",
    "            lk_new = val_loglhood(theta, Y0, X, debug, method=method)\n",
    "            # print('new_lk: {}'.format(lk_new))\n",
    "        #print('Quantity of -np.infs: {}'.format(c))\n",
    "        if method == 'normal':\n",
    "            logalpha = min([lk_new - lk_old + np.log(q.pdf(samples_mh[-1], loc=x_new) \\\n",
    "                                                     / q.pdf(x_new, loc=samples_mh[-1])), 0])\n",
    "        elif method == 'personalized':\n",
    "            logalpha = min([lk_new - lk_old + np.log(q_eval_old / q_eval_new), 0])\n",
    "        alpha = np.exp(logalpha)\n",
    "        u = stats.uniform.rvs()\n",
    "        if u < alpha:\n",
    "            #print('acepted')\n",
    "            samples_mh.append(theta[j])\n",
    "            lk_old = lk_new\n",
    "        else:\n",
    "            #print('rejected')\n",
    "            samples_mh.append(samples_mh[-1])\n",
    "            theta[j] = samples_mh[-1]\n",
    "    return np.array(samples_mh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/chrisams/Documents/datasets/data_TAIM/processed/'\n",
    "q = stats.norm\n",
    "K = 3\n",
    "p = 1\n",
    "iters = 2\n",
    "debug = False\n",
    "mh_iters = 10\n",
    "n_rows = 10000 # Number of rows of the data to load\n",
    "method = 'personalized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = gibbs_sampling(iters, DATA_PATH, K, p, q, mh_iters=mh_iters, n_rows=n_rows, debug=debug, method=method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tiempo normal: 108.39511632919312\n",
    "\n",
    "tiempo personalizado :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/chrisams/Documents/datasets/data_TAIM/processed/'\n",
    "K = 3\n",
    "theta_old = np.ones(K*K*2+K*2)\n",
    "j = 0\n",
    "user_std = 1\n",
    "n_rows = 10000\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y0, X = load_data(DATA_PATH, K, 1, resample_rule='10T', n_rows=n_rows)\n",
    "theta_new, q_eval_new, q_eval_old = jump_dst(theta_old, j, user_std, K)\n",
    "lk_new = val_loglhood(theta_new, Y0, X, debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y0.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.pdf(1, loc=2, scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.pdf(1, loc=2, scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(A)\n",
    "U = np.array([[7, 8, 9], [10, 11, 12], [13, 14, 15]])\n",
    "print(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Av = A.T.reshape(-1)\n",
    "print(Av)\n",
    "Uv = U.T.reshape(-1)\n",
    "print(Uv)\n",
    "theta = np.concatenate([Av, Uv])\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kv = 3\n",
    "pv = 1\n",
    "A = np.reshape(theta[:pv*Kv**2],(Kv*pv,Kv)).swapaxes(0,1)\n",
    "CovU = np.reshape(theta[pv*Kv**2:],(Kv,Kv)).swapaxes(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(A)\n",
    "print(CovU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3\n",
    "a = np.array([[1, 2, 3], [2, 1, 4], [3, 4, 5]])\n",
    "b = np.array([[1, 2, 16], [2, 1, 4], [16, 4, 5]])\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_valuesA, eig_vecA = np.linalg.eig(a)\n",
    "eig_valuesB, eig_vecB = np.linalg.eig(b)\n",
    "theta = np.concatenate((eig_vecA.reshape(-1),eig_vecB.reshape(-1),\n",
    "                        eig_valuesA,eig_valuesB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_vecA = np.reshape(theta[:(K*K)],(K,K))\n",
    "samp_vecU = np.reshape(theta[(K*K):(K*K*2)],(K,K))\n",
    "samp_valA = np.diag(theta[(K*K*2):(K*K*2+K)])\n",
    "samp_valU = np.diag(theta[(K*K*2+K):(K*K*2+K*2)])\n",
    "\n",
    "A = samp_vecA @ samp_valA @np.linalg.inv(samp_vecA)\n",
    "U = samp_vecU @ samp_valU @np.linalg.inv(samp_vecU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(A)\n",
    "print(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
