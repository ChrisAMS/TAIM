{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import scipy.stats as stats\n",
    "from utils import load_data, val_loglhood, loglhood, jump_dst, reconstruct_coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gibbs Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gibbs_sampling(iters, data_path, K, p, q, mh_iters=1,n_rows=None, debug=False, method='normal'):\n",
    "    \"\"\"\n",
    "    data_path: path where data is saved.\n",
    "    K: number of plants (n_plants in load_data function).\n",
    "    p: past time to be considered.\n",
    "    q: sample distribution for parameters.\n",
    "    \"\"\"\n",
    "    print('Loading data...')\n",
    "    Y0, X = load_data(data_path, K, p, resample_rule='10T', n_rows=n_rows)\n",
    "    if debug:\n",
    "        print('Y0 shape: {}'.format(Y0.shape))\n",
    "        print('X shape: {}'.format(X.shape))\n",
    "    # Theta is the vector of all parameters that will be sampled.\n",
    "    # A and CovU are reshaped un a 1-D vector theta.\n",
    "    theta = init_parameters(K, p, q, Y0, X, debug=debug, method=method)\n",
    "    if debug:\n",
    "        print('Parameters intialized!')\n",
    "    samples = []\n",
    "    for i in range(iters):\n",
    "        start_it = time.time()\n",
    "        print('Iteration {}'.format(i))\n",
    "        # Loop over all parameters and for each parameter theta[j],\n",
    "        # do a MH sampling over the distribution of theta[j] given theta[-j].\n",
    "        for j in range(theta.shape[0]):\n",
    "            start = time.time()\n",
    "            mh_samples = metropolis_hastings(theta, j, q, mh_iters, Y0, X, K, debug, method=method)\n",
    "            end = time.time()\n",
    "            print('Time for sampling theta[{}]: {}'.format(j, end - start))\n",
    "            theta[j] = np.random.choice(mh_samples)\n",
    "        if p == 1 and method == 'personalized':\n",
    "            A, CovU = reconstruct_coefs(theta, K)\n",
    "        else:\n",
    "            A    = np.reshape(theta[:p*K**2],(K*p,K)).swapaxes(0,1)\n",
    "            CovU = np.reshape(theta[p*K**2:],(K,K)).swapaxes(0,1)\n",
    "            CovU = np.dot(CovU.T,CovU)\n",
    "        samples.append([A, CovU])\n",
    "        end_it = time.time()\n",
    "        print('Time for iteration {}: {}'.format(i, end_it - start_it))\n",
    "    print('Finished!')\n",
    "    return samples\n",
    "        \n",
    "    \n",
    "def init_parameters(K, p, q, Y0, X, method='normal', debug=False):\n",
    "    \"\"\"\n",
    "    Initialization of parameters. This functions search a matrix A\n",
    "    and a matrix CovU that satisfy some conditions that A and CovU\n",
    "    must satisfy.\n",
    "    \"\"\"\n",
    "    if debug:\n",
    "        print('Initializing parameters...')\n",
    "    while True:\n",
    "        theta = np.zeros(K ** 2 * (p + 1))\n",
    "        for i in range(theta.shape[0]):\n",
    "            theta[i] = q.rvs()\n",
    "\n",
    "        # Force CovU to be positive semidefinite.\n",
    "        covu = np.reshape(theta[-K**2:], (K, K)).T\n",
    "        covu = np.dot(covu.T, covu)\n",
    "        theta[-K**2:] = np.reshape(covu, K**2)\n",
    "        \n",
    "        lk = val_loglhood(theta, Y0, X, debug, method=method, init_params=True)\n",
    "        if debug:\n",
    "            print('LK = {}'.format(lk))\n",
    "        if lk != -np.inf:\n",
    "            print('lk init: {}'.format(lk))\n",
    "            if p == 1 and method == 'personalized':\n",
    "                A = np.reshape(theta[:p*K**2],(K*p,K)).swapaxes(0,1)\n",
    "                print(A)\n",
    "                print(covu)\n",
    "                eig_valuesA, eig_vecA = np.linalg.eig(A)\n",
    "                eig_valuesB, eig_vecB = np.linalg.eig(covu)\n",
    "                theta = np.concatenate((eig_vecA.reshape(-1), eig_vecB.reshape(-1),\n",
    "                                        eig_valuesA, eig_valuesB))\n",
    "                print(theta)\n",
    "                if np.all(np.isreal(eig_valuesA)):\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "    return theta\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metropolis Hastings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metropolis Hastings\n",
    "\n",
    "def metropolis_hastings(theta, j, q, iters, Y0, X, K, debug, method='normal'):\n",
    "    \"\"\"\n",
    "    theta: theta vector with all parameters.\n",
    "    j: theta index of the parameter currently been sampled.\n",
    "    q: jumping distribution.\n",
    "    \"\"\"\n",
    "    user_std = 1\n",
    "    samples_mh = [theta[j]] # start sample.\n",
    "    lk_old = val_loglhood(theta, Y0, X, debug, method=method)\n",
    "    print('init lk: {}'.format(lk_old))\n",
    "    for t in range(iters):\n",
    "        lk_new = -np.inf\n",
    "        c = -1\n",
    "        while lk_new == -np.inf:\n",
    "            c += 1\n",
    "            if method == 'normal':\n",
    "                x_new = q.rvs(loc=samples_mh[-1], scale=1)\n",
    "                theta[j] = x_new\n",
    "            elif method == 'personalized':\n",
    "                theta, q_eval_new, q_eval_old = jump_dst(theta, j, user_std, K)\n",
    "            lk_new = val_loglhood(theta, Y0, X, debug, method=method)\n",
    "            # print('new_lk: {}'.format(lk_new))\n",
    "        #print('Quantity of -np.infs: {}'.format(c))\n",
    "        if method == 'normal':\n",
    "            logalpha = min([lk_new - lk_old + np.log(q.pdf(samples_mh[-1], loc=x_new) \\\n",
    "                                                     / q.pdf(x_new, loc=samples_mh[-1])), 0])\n",
    "        elif method == 'personalized':\n",
    "            logalpha = min([lk_new - lk_old + np.log(q_eval_old / q_eval_new), 0])\n",
    "        alpha = np.exp(logalpha)\n",
    "        u = stats.uniform.rvs()\n",
    "        if u < alpha:\n",
    "            #print('acepted')\n",
    "            samples_mh.append(theta[j])\n",
    "            lk_old = lk_new\n",
    "        else:\n",
    "            #print('rejected')\n",
    "            samples_mh.append(samples_mh[-1])\n",
    "            theta[j] = samples_mh[-1]\n",
    "    return np.array(samples_mh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/chrisams/Documents/datasets/data_TAIM/processed/'\n",
    "q = stats.norm\n",
    "K = 3\n",
    "p = 1\n",
    "iters = 2\n",
    "debug = False\n",
    "mh_iters = 10\n",
    "n_rows = 10000 # Number of rows of the data to load\n",
    "method = 'personalized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "lk init: -591159514.4846909\n",
      "[[ 0.30026513  0.39074505  0.13886574]\n",
      " [ 1.36693547 -0.79227451  1.0587391 ]\n",
      " [-0.22176719 -0.33006159 -0.16244046]]\n",
      "[[ 0.26155615 -0.68579614  0.25476496]\n",
      " [-0.68579614  3.08059612 -0.08844742]\n",
      " [ 0.25476496 -0.08844742  0.52334906]]\n",
      "[-7.54527810e-01 -3.19290168e-01 -5.04691976e-01 -3.98443365e-01\n",
      "  9.00585468e-01  2.70788841e-01  5.21469720e-01  2.94956951e-01\n",
      "  8.19731305e-01 -2.27914912e-01  8.94621265e-01  3.84327444e-01\n",
      "  9.72242573e-01  1.87651778e-01  1.39754030e-01 -5.29071993e-02\n",
      " -4.05511531e-01  9.12557520e-01  4.10632828e-01 -9.30147710e-01\n",
      " -1.34934949e-01  3.24617483e+00  2.22742182e-03  6.17099080e-01]\n",
      "Iteration 0\n",
      "init lk: -1312579.3533358953\n",
      "Time for sampling theta[0]: 6.108119964599609\n",
      "init lk: -571736.7083982422\n",
      "Time for sampling theta[1]: 6.0409159660339355\n",
      "init lk: -571736.7083982422\n",
      "Time for sampling theta[2]: 6.058082342147827\n",
      "init lk: -205752.80885278282\n",
      "Time for sampling theta[3]: 6.10756254196167\n",
      "init lk: -199227.81326257403\n",
      "Time for sampling theta[4]: 6.025214433670044\n",
      "init lk: -186473.56715268042\n",
      "Time for sampling theta[5]: 5.9961066246032715\n",
      "init lk: -186473.56715268042\n",
      "Time for sampling theta[6]: 6.167470932006836\n",
      "init lk: -186139.57057342946\n",
      "Time for sampling theta[7]: 6.05864953994751\n",
      "init lk: -186139.57057342946\n",
      "Time for sampling theta[8]: 6.143179416656494\n",
      "init lk: -186139.57057342946\n",
      "Time for sampling theta[9]: 6.0695765018463135\n",
      "init lk: 230101.73698796929\n",
      "Time for sampling theta[10]: 5.996306896209717\n",
      "init lk: 321618.6484462382\n",
      "Time for sampling theta[11]: 6.068674564361572\n",
      "init lk: 850573.2420883662\n",
      "Time for sampling theta[12]: 5.990728139877319\n",
      "init lk: 1938246.4650505425\n",
      "Time for sampling theta[13]: 6.044674634933472\n",
      "init lk: 87901216.9712927\n",
      "Time for sampling theta[14]: 6.129176139831543\n",
      "init lk: 732711902.3336105\n",
      "Time for sampling theta[15]: 6.076959848403931\n",
      "init lk: 732711902.3336105\n",
      "Time for sampling theta[16]: 6.033763408660889\n",
      "init lk: 732711902.3336105\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-942bac030f96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgibbs_sampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmh_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmh_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-72e4ef1b2673>\u001b[0m in \u001b[0;36mgibbs_sampling\u001b[0;34m(iters, data_path, K, p, q, mh_iters, n_rows, debug, method)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mmh_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetropolis_hastings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmh_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Time for sampling theta[{}]: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-6502230a2002>\u001b[0m in \u001b[0;36mmetropolis_hastings\u001b[0;34m(theta, j, q, iters, Y0, X, K, debug, method)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'personalized'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_eval_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_eval_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjump_dst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mlk_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_loglhood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0;31m# print('new_lk: {}'.format(lk_new))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m#print('Quantity of -np.infs: {}'.format(c))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/repos/TAIM/utils.py\u001b[0m in \u001b[0;36mval_loglhood\u001b[0;34m(theta, Y0, X, flag_print, method, init_params)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meig_val_A\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#Parametros matrices A,CovU validos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloglhood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCovU\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflag_print\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#se muestran matrices A, CovU construidas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Matriz A resulante:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/repos/TAIM/utils.py\u001b[0m in \u001b[0;36mloglhood\u001b[0;34m(CovU, Y0, A, X)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m#T = Y0.shape[1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mtrace_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCovU\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mY0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCovU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "samples = gibbs_sampling(iters, DATA_PATH, K, p, q, mh_iters=mh_iters, n_rows=n_rows, debug=debug, method=method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tiempo normal: 108.39511632919312\n",
    "\n",
    "tiempo personalizado :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/chrisams/Documents/datasets/data_TAIM/processed/'\n",
    "K = 3\n",
    "theta_old = np.ones(K*K*2+K*2)\n",
    "j = 0\n",
    "user_std = 1\n",
    "n_rows = 10000\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y0, X = load_data(DATA_PATH, K, 1, resample_rule='10T', n_rows=n_rows)\n",
    "theta_new, q_eval_new, q_eval_old = jump_dst(theta_old, j, user_std, K)\n",
    "lk_new = val_loglhood(theta_new, Y0, X, debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y0.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.pdf(1, loc=2, scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.pdf(1, loc=2, scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(A)\n",
    "U = np.array([[7, 8, 9], [10, 11, 12], [13, 14, 15]])\n",
    "print(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Av = A.T.reshape(-1)\n",
    "print(Av)\n",
    "Uv = U.T.reshape(-1)\n",
    "print(Uv)\n",
    "theta = np.concatenate([Av, Uv])\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kv = 3\n",
    "pv = 1\n",
    "A = np.reshape(theta[:pv*Kv**2],(Kv*pv,Kv)).swapaxes(0,1)\n",
    "CovU = np.reshape(theta[pv*Kv**2:],(Kv,Kv)).swapaxes(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(A)\n",
    "print(CovU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3\n",
    "a = np.array([[1, 2, 3], [2, 1, 4], [3, 4, 5]])\n",
    "b = np.array([[1, 2, 16], [2, 1, 4], [16, 4, 5]])\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_valuesA, eig_vecA = np.linalg.eig(a)\n",
    "eig_valuesB, eig_vecB = np.linalg.eig(b)\n",
    "theta = np.concatenate((eig_vecA.reshape(-1),eig_vecB.reshape(-1),\n",
    "                        eig_valuesA,eig_valuesB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_vecA = np.reshape(theta[:(K*K)],(K,K))\n",
    "samp_vecU = np.reshape(theta[(K*K):(K*K*2)],(K,K))\n",
    "samp_valA = np.diag(theta[(K*K*2):(K*K*2+K)])\n",
    "samp_valU = np.diag(theta[(K*K*2+K):(K*K*2+K*2)])\n",
    "\n",
    "A = samp_vecA @ samp_valA @np.linalg.inv(samp_vecA)\n",
    "U = samp_vecU @ samp_valU @np.linalg.inv(samp_vecU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(A)\n",
    "print(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
